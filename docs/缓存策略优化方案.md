# 缓存策略优化方案

## 1. 现状分析

### 1.1 当前缓存实现

| 模块 | 缓存类型 | 缓存容量 | TTL | 缓存内容 |
|------|---------|---------|-----|---------|
| `data_fetcher.py` | TTLCache | 1 | 1小时 | 股票列表 |
| `stock_screener.py` | TTLCache | 1 | 5分钟 | 全市场股票快照 |
| `fundamental_analyzer.py` | TTLCache | 100 | 30分钟 | 基本面数据 |
| `config.py` | lru_cache | 1 | 永久 | 配置实例 |

### 1.2 存在的问题

1. **缓存策略分散**：各模块独立实现缓存，缺乏统一管理
2. **K线数据无缓存**：每次请求都调用 AKShare API，造成不必要的网络开销
3. **实时行情无缓存**：高频请求场景下 API 压力大
4. **硬编码配置**：TTL 等参数硬编码，无法动态调整
5. **无持久化/跨进程共享**：仅支持单进程内存缓存，服务重启即失效，无法在同机多进程之间复用
6. **无缓存监控**：缺少命中率、内存占用等监控指标
7. **无预热机制**：冷启动时首次请求延迟较高
8. **无失效通知**：缓存失效时无法主动通知订阅者

---

## 2. 优化目标

1. **统一缓存管理**：建立集中式缓存管理模块
2. **分层缓存架构**：L1（内存） + L2（SQLite）两级缓存
3. **智能缓存策略**：根据数据特性设置不同的缓存策略
4. **可观测性**：提供缓存监控指标
5. **高可用**：支持缓存降级和故障恢复

---

## 3. 缓存架构设计

### 3.1 分层缓存架构

```
┌─────────────────────────────────────────────────────────┐
│                      应用层                              │
├─────────────────────────────────────────────────────────┤
│                   CacheManager                           │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────┐ │
│  │ 股票列表缓存 │  │ K线数据缓存 │  │ 基本面数据缓存  │ │
│  └─────────────┘  └─────────────┘  └─────────────────┘ │
├─────────────────────────────────────────────────────────┤
│           L1 Cache (本地内存 - TTLCache/LRU)            │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────┐ │
│  │   热点数据   │  │  最近访问   │  │    高频数据     │ │
│  └─────────────┘  └─────────────┘  └─────────────────┘ │
├─────────────────────────────────────────────────────────┤
│               L2 Cache (SQLite - 持久化)                │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────┐ │
│  │  持久化数据  │  │  进程共享   │  │   过期清理     │ │
│  └─────────────┘  └─────────────┘  └─────────────────┘ │
├─────────────────────────────────────────────────────────┤
│                    数据源层                              │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────┐ │
│  │   AKShare   │  │   数据库    │  │    外部 API     │ │
│  └─────────────┘  └─────────────┘  └─────────────────┘ │
└─────────────────────────────────────────────────────────┘
```

说明：L2 建议使用独立的 `cache.db`，避免与业务库 `stock.db` 产生写锁竞争；如需复用同一库，请启用 WAL 并限制写入频率。

### 3.2 缓存分类与策略

| 数据类型 | 更新频率 | 建议 TTL | 缓存层级 | 优先级 |
|---------|---------|---------|---------|--------|
| 股票列表 | 低（每日） | 4小时 | L1 + L2 | 高 |
| 日K线（历史） | 低 | 24小时 | L1 + L2 | 高 |
| 日K线（当日） | 每日收盘 | 至收盘 | L1 | 中 |
| 分钟K线 | 实时 | 1分钟 | L1 | 低 |
| 实时行情 | 实时 | 3秒 | L1 | 低 |
| 全市场快照 | 中 | 5分钟 | L1 + L2 | 高 |
| 公司概况 | 低 | 24小时 | L1 + L2 | 中 |
| 财务报表 | 季度 | 6小时 | L1 + L2 | 中 |
| 分红历史 | 年度 | 24小时 | L1 + L2 | 低 |
| 股东信息 | 季度 | 6小时 | L1 + L2 | 低 |

---

## 4. 核心模块设计

### 4.1 CacheManager 接口设计

```python
# backend/app/core/cache_manager.py

from abc import ABC, abstractmethod
from typing import Any, Optional, Callable, TypeVar
from datetime import timedelta
from enum import Enum
import asyncio

T = TypeVar('T')

class CacheLevel(Enum):
    """缓存层级"""
    L1_MEMORY = "memory"      # 本地内存
    L2_SQLITE = "sqlite"      # SQLite 持久化
    BOTH = "both"             # 两级缓存


class CacheConfig:
    """缓存配置"""
    def __init__(
        self,
        ttl: timedelta,
        max_size: int = 1000,
        level: CacheLevel = CacheLevel.L1_MEMORY,
        namespace: str = "default",
        serialize: bool = True
    ):
        self.ttl = ttl
        self.max_size = max_size
        self.level = level
        self.namespace = namespace
        self.serialize = serialize


class CacheBackend(ABC):
    """缓存后端抽象接口"""

    @abstractmethod
    async def get(self, key: str) -> Optional[Any]:
        """获取缓存"""
        pass

    @abstractmethod
    async def set(self, key: str, value: Any, ttl: timedelta) -> bool:
        """设置缓存"""
        pass

    @abstractmethod
    async def delete(self, key: str) -> bool:
        """删除缓存"""
        pass

    @abstractmethod
    async def exists(self, key: str) -> bool:
        """检查缓存是否存在"""
        pass

    @abstractmethod
    async def clear_namespace(self, namespace: str) -> int:
        """清除指定命名空间的所有缓存"""
        pass


class CacheManager:
    """统一缓存管理器"""

    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if hasattr(self, '_initialized'):
            return
        self._initialized = True
        self._l1_cache: CacheBackend = None  # 内存缓存
        self._l2_cache: CacheBackend = None  # SQLite 缓存
        self._stats = CacheStats()

    async def get(
        self,
        key: str,
        config: CacheConfig,
        fetch_func: Optional[Callable[[], T]] = None
    ) -> Optional[T]:
        """
        获取缓存，支持回源加载

        Args:
            key: 缓存键
            config: 缓存配置
            fetch_func: 缓存未命中时的数据获取函数
        """
        full_key = self._build_key(key, config.namespace)

        # 尝试从 L1 获取
        if config.level in (CacheLevel.L1_MEMORY, CacheLevel.BOTH):
            value = await self._l1_cache.get(full_key)
            if value is not None:
                self._stats.record_hit("L1")
                return value

        # 尝试从 L2 获取
        if config.level in (CacheLevel.L2_SQLITE, CacheLevel.BOTH):
            value = await self._l2_cache.get(full_key)
            if value is not None:
                self._stats.record_hit("L2")
                # 回填 L1
                if config.level == CacheLevel.BOTH:
                    await self._l1_cache.set(full_key, value, config.ttl)
                return value

        # 缓存未命中，回源加载
        self._stats.record_miss()
        if fetch_func:
            value = await fetch_func() if asyncio.iscoroutinefunction(fetch_func) else fetch_func()
            if value is not None:
                await self.set(key, value, config)
            return value

        return None

    async def set(self, key: str, value: Any, config: CacheConfig) -> bool:
        """设置缓存"""
        full_key = self._build_key(key, config.namespace)

        success = True
        if config.level in (CacheLevel.L1_MEMORY, CacheLevel.BOTH):
            success &= await self._l1_cache.set(full_key, value, config.ttl)
        if config.level in (CacheLevel.L2_SQLITE, CacheLevel.BOTH):
            success &= await self._l2_cache.set(full_key, value, config.ttl)

        return success

    def _build_key(self, key: str, namespace: str) -> str:
        """构建完整的缓存键"""
        return f"{namespace}:{key}"

    def get_stats(self) -> dict:
        """获取缓存统计信息"""
        return self._stats.to_dict()

    async def clear_namespace(self, namespace: str) -> int:
        """清除指定命名空间的所有缓存"""
        total = 0
        if self._l1_cache:
            total += await self._l1_cache.clear_namespace(namespace)
        if self._l2_cache:
            total += await self._l2_cache.clear_namespace(namespace)
        return total


class CacheStats:
    """缓存统计"""
    def __init__(self):
        self.l1_hits = 0
        self.l2_hits = 0
        self.misses = 0

    def record_hit(self, level: str):
        if level == "L1":
            self.l1_hits += 1
        else:
            self.l2_hits += 1

    def record_miss(self):
        self.misses += 1

    @property
    def hit_rate(self) -> float:
        total = self.l1_hits + self.l2_hits + self.misses
        return (self.l1_hits + self.l2_hits) / total if total > 0 else 0

    def to_dict(self) -> dict:
        return {
            "l1_hits": self.l1_hits,
            "l2_hits": self.l2_hits,
            "misses": self.misses,
            "hit_rate": round(self.hit_rate * 100, 2)
        }
```

### 4.2 内存缓存后端实现

```python
# backend/app/core/cache_backends/memory.py

from cachetools import TTLCache
from datetime import timedelta
from typing import Any, Optional, Dict
import threading
import asyncio

class MemoryCacheBackend(CacheBackend):
    """基于 cachetools 的内存缓存后端"""

    def __init__(self, default_max_size: int = 10000):
        self._caches: Dict[str, TTLCache] = {}
        self._lock = threading.RLock()
        self._default_max_size = default_max_size

    def _get_or_create_cache(self, namespace: str, ttl: timedelta, max_size: int) -> TTLCache:
        """获取或创建指定命名空间的缓存"""
        cache_key = f"{namespace}:{int(ttl.total_seconds())}"
        with self._lock:
            if cache_key not in self._caches:
                self._caches[cache_key] = TTLCache(
                    maxsize=max_size,
                    ttl=ttl.total_seconds()
                )
            return self._caches[cache_key]

    async def get(self, key: str) -> Optional[Any]:
        # 遍历所有缓存查找（简化实现）
        for cache in self._caches.values():
            if key in cache:
                return cache[key]
        return None

    async def set(self, key: str, value: Any, ttl: timedelta) -> bool:
        try:
            namespace = key.split(':')[0] if ':' in key else 'default'
            cache = self._get_or_create_cache(namespace, ttl, self._default_max_size)
            cache[key] = value
            return True
        except Exception:
            return False

    async def delete(self, key: str) -> bool:
        for cache in self._caches.values():
            if key in cache:
                del cache[key]
                return True
        return False

    async def exists(self, key: str) -> bool:
        for cache in self._caches.values():
            if key in cache:
                return True
        return False

    async def clear_namespace(self, namespace: str) -> int:
        count = 0
        keys_to_delete = []
        for cache_key, cache in self._caches.items():
            if cache_key.startswith(namespace):
                count += len(cache)
                keys_to_delete.append(cache_key)

        for key in keys_to_delete:
            del self._caches[key]

        return count
```

### 4.3 SQLite 缓存后端实现（可选）

```python
# backend/app/core/cache_backends/sqlite.py

import aiosqlite
import asyncio
import pickle
import time
from datetime import timedelta
from typing import Any, Optional

class SQLiteCacheBackend(CacheBackend):
    """SQLite 缓存后端（持久化）"""

    def __init__(self, db_path: str = "./data/cache.db"):
        self._db_path = db_path
        self._conn: Optional[aiosqlite.Connection] = None
        self._lock = asyncio.Lock()

    async def _ensure_conn(self) -> aiosqlite.Connection:
        if self._conn is None:
            self._conn = await aiosqlite.connect(self._db_path)
            await self._conn.execute("PRAGMA journal_mode=WAL;")
            await self._conn.execute("PRAGMA synchronous=NORMAL;")
            await self._conn.execute("PRAGMA busy_timeout=5000;")
            await self._conn.execute(
                """
                CREATE TABLE IF NOT EXISTS cache_entries (
                    key TEXT PRIMARY KEY,
                    value BLOB NOT NULL,
                    expires_at INTEGER NOT NULL,
                    created_at INTEGER NOT NULL
                )
                """
            )
            await self._conn.execute(
                "CREATE INDEX IF NOT EXISTS idx_cache_expires ON cache_entries(expires_at)"
            )
            await self._conn.commit()
        return self._conn

    async def get(self, key: str) -> Optional[Any]:
        conn = await self._ensure_conn()
        async with self._lock:
            cursor = await conn.execute(
                "SELECT value, expires_at FROM cache_entries WHERE key = ?",
                (key,)
            )
            row = await cursor.fetchone()
            await cursor.close()
            if not row:
                return None
            value_blob, expires_at = row
            if expires_at <= int(time.time()):
                await conn.execute("DELETE FROM cache_entries WHERE key = ?", (key,))
                await conn.commit()
                return None
            return pickle.loads(value_blob)

    async def set(self, key: str, value: Any, ttl: timedelta) -> bool:
        conn = await self._ensure_conn()
        expires_at = int(time.time() + ttl.total_seconds())
        payload = pickle.dumps(value, protocol=pickle.HIGHEST_PROTOCOL)
        async with self._lock:
            await conn.execute(
                """
                INSERT INTO cache_entries (key, value, expires_at, created_at)
                VALUES (?, ?, ?, ?)
                ON CONFLICT(key) DO UPDATE SET value=excluded.value, expires_at=excluded.expires_at
                """,
                (key, payload, expires_at, int(time.time()))
            )
            await conn.commit()
        return True

    async def delete(self, key: str) -> bool:
        conn = await self._ensure_conn()
        async with self._lock:
            cursor = await conn.execute("DELETE FROM cache_entries WHERE key = ?", (key,))
            await conn.commit()
            return cursor.rowcount > 0

    async def exists(self, key: str) -> bool:
        conn = await self._ensure_conn()
        async with self._lock:
            cursor = await conn.execute(
                "SELECT 1 FROM cache_entries WHERE key = ? AND expires_at > ?",
                (key, int(time.time()))
            )
            row = await cursor.fetchone()
            await cursor.close()
            return row is not None

    async def clear_namespace(self, namespace: str) -> int:
        conn = await self._ensure_conn()
        async with self._lock:
            cursor = await conn.execute(
                "DELETE FROM cache_entries WHERE key LIKE ?",
                (f"{namespace}:%",)
            )
            await conn.commit()
            return cursor.rowcount

    async def purge_expired(self) -> int:
        """清理过期缓存（可用于定时任务）"""
        conn = await self._ensure_conn()
        async with self._lock:
            cursor = await conn.execute(
                "DELETE FROM cache_entries WHERE expires_at <= ?",
                (int(time.time()),)
            )
            await conn.commit()
            return cursor.rowcount

    async def close(self) -> None:
        if self._conn:
            await self._conn.close()
            self._conn = None
```

---

## 5. 数据获取层缓存集成

### 5.1 K线数据缓存优化

```python
# backend/app/core/data_fetcher.py (优化后)

from datetime import timedelta
from app.core.cache_manager import CacheManager, CacheConfig, CacheLevel

# 缓存配置
CACHE_CONFIGS = {
    "stock_list": CacheConfig(
        ttl=timedelta(hours=4),
        max_size=1,
        level=CacheLevel.BOTH,
        namespace="stock"
    ),
    "daily_kline_history": CacheConfig(
        ttl=timedelta(hours=24),
        max_size=500,
        level=CacheLevel.BOTH,
        namespace="kline"
    ),
    "daily_kline_today": CacheConfig(
        ttl=timedelta(minutes=5),
        max_size=500,
        level=CacheLevel.L1_MEMORY,
        namespace="kline"
    ),
    "realtime_quote": CacheConfig(
        ttl=timedelta(seconds=3),
        max_size=1000,
        level=CacheLevel.L1_MEMORY,
        namespace="quote"
    ),
    "intraday": CacheConfig(
        ttl=timedelta(seconds=60),
        max_size=500,
        level=CacheLevel.L1_MEMORY,
        namespace="intraday"
    )
}

class StockDataFetcher:
    """优化后的股票数据获取器"""

    _cache = CacheManager()

    @classmethod
    async def get_daily_kline_cached(
        cls,
        code: str,
        start_date: str,
        end_date: str,
        adjust: str = "qfq"
    ) -> pd.DataFrame:
        """带缓存的日K线获取"""

        # 判断是否包含当日数据
        today = datetime.now().strftime("%Y%m%d")
        is_today_included = end_date >= today

        # 选择缓存配置
        config = (CACHE_CONFIGS["daily_kline_today"]
                  if is_today_included
                  else CACHE_CONFIGS["daily_kline_history"])

        cache_key = f"kline:{code}:{start_date}:{end_date}:{adjust}"

        # 定义回源函数
        async def fetch():
            return await cls.get_daily_kline_async(code, start_date, end_date, adjust)

        return await cls._cache.get(cache_key, config, fetch)

    @classmethod
    async def get_realtime_quote_cached(cls, code: str) -> Optional[Dict[str, Any]]:
        """带缓存的实时行情获取"""

        cache_key = f"quote:{code}"
        config = CACHE_CONFIGS["realtime_quote"]

        async def fetch():
            return await cls.get_realtime_quote_async(code)

        return await cls._cache.get(cache_key, config, fetch)
```

### 5.2 批量请求优化

```python
# backend/app/core/batch_fetcher.py

import asyncio
from typing import List, Dict, Any
from datetime import timedelta

class BatchFetcher:
    """批量数据获取器，支持请求合并和并发控制"""

    def __init__(self, max_concurrent: int = 10):
        self._semaphore = asyncio.Semaphore(max_concurrent)
        self._pending_requests: Dict[str, asyncio.Future] = {}

    async def fetch_multiple_quotes(
        self,
        codes: List[str]
    ) -> Dict[str, Dict[str, Any]]:
        """批量获取多只股票的实时行情"""

        results = {}
        tasks = []

        for code in codes:
            # 检查是否有相同请求正在进行（请求合并）
            if code in self._pending_requests:
                tasks.append((code, self._pending_requests[code]))
            else:
                future = asyncio.ensure_future(self._fetch_single(code))
                self._pending_requests[code] = future
                tasks.append((code, future))

        # 等待所有请求完成
        for code, task in tasks:
            try:
                results[code] = await task
            except Exception as e:
                print(f"Error fetching {code}: {e}")
                results[code] = None
            finally:
                self._pending_requests.pop(code, None)

        return results

    async def _fetch_single(self, code: str) -> Dict[str, Any]:
        """单个请求（带并发控制）"""
        async with self._semaphore:
            return await StockDataFetcher.get_realtime_quote_cached(code)
```

---

## 6. 缓存预热策略

### 6.1 预热管理器

```python
# backend/app/core/cache_warmer.py

import asyncio
from typing import List
from datetime import datetime

class CacheWarmer:
    """缓存预热管理器"""

    def __init__(self):
        self._is_warming = False

    async def warm_on_startup(self):
        """服务启动时预热缓存"""
        if self._is_warming:
            return

        self._is_warming = True
        print("[CacheWarmer] Starting cache warm-up...")

        try:
            # 1. 预热股票列表
            await self._warm_stock_list()

            # 2. 预热热门股票的K线数据
            await self._warm_popular_stocks()

            # 3. 预热全市场快照（用于筛选器）
            await self._warm_market_snapshot()

            print("[CacheWarmer] Cache warm-up completed")
        except Exception as e:
            print(f"[CacheWarmer] Warm-up failed: {e}")
        finally:
            self._is_warming = False

    async def _warm_stock_list(self):
        """预热股票列表"""
        print("[CacheWarmer] Warming stock list...")
        await StockDataFetcher.get_stock_list_async()

    async def _warm_popular_stocks(self):
        """预热热门股票数据"""
        # 定义热门股票列表（可从配置或数据库读取）
        popular_codes = [
            "000001.SZ",  # 平安银行
            "600519.SH",  # 贵州茅台
            "000858.SZ",  # 五粮液
            "601318.SH",  # 中国平安
            "600036.SH",  # 招商银行
        ]

        print(f"[CacheWarmer] Warming {len(popular_codes)} popular stocks...")

        tasks = [
            StockDataFetcher.get_daily_kline_cached(
                code,
                start_date=(datetime.now() - timedelta(days=365)).strftime("%Y%m%d"),
                end_date=datetime.now().strftime("%Y%m%d")
            )
            for code in popular_codes
        ]

        await asyncio.gather(*tasks, return_exceptions=True)

    async def _warm_market_snapshot(self):
        """预热全市场快照"""
        print("[CacheWarmer] Warming market snapshot...")
        await StockScreener.get_all_stocks_data()


# 在 FastAPI 启动时调用
# backend/app/main.py
from app.core.cache_warmer import CacheWarmer

@app.on_event("startup")
async def startup_event():
    warmer = CacheWarmer()
    # 后台执行预热，不阻塞启动
    asyncio.create_task(warmer.warm_on_startup())
```

---

## 7. 缓存监控与运维

### 7.1 监控 API

```python
# backend/app/api/v1/cache.py

from fastapi import APIRouter
from app.core.cache_manager import CacheManager

router = APIRouter()

@router.get("/stats")
async def get_cache_stats():
    """获取缓存统计信息"""
    cache = CacheManager()
    return {
        "status": "ok",
        "stats": cache.get_stats(),
        "timestamp": datetime.now().isoformat()
    }

@router.post("/clear/{namespace}")
async def clear_cache(namespace: str):
    """清除指定命名空间的缓存"""
    cache = CacheManager()
    count = await cache.clear_namespace(namespace)
    return {
        "status": "ok",
        "cleared_count": count,
        "namespace": namespace
    }

@router.post("/warm")
async def trigger_warm():
    """触发缓存预热"""
    warmer = CacheWarmer()
    asyncio.create_task(warmer.warm_on_startup())
    return {"status": "ok", "message": "Warm-up started"}
```

### 7.2 日志与告警

```python
# backend/app/core/cache_monitor.py

import logging
from datetime import datetime, timedelta

logger = logging.getLogger("cache")

class CacheMonitor:
    """缓存监控器"""

    def __init__(self, alert_threshold: float = 0.5):
        self._alert_threshold = alert_threshold  # 命中率告警阈值
        self._last_alert_time = None

    async def check_health(self) -> dict:
        """检查缓存健康状态"""
        cache = CacheManager()
        stats = cache.get_stats()

        health = {
            "status": "healthy",
            "hit_rate": stats["hit_rate"],
            "l1_hits": stats["l1_hits"],
            "l2_hits": stats["l2_hits"],
            "misses": stats["misses"],
            "timestamp": datetime.now().isoformat()
        }

        # 检查命中率
        if stats["hit_rate"] < self._alert_threshold * 100:
            health["status"] = "warning"
            health["message"] = f"Cache hit rate below {self._alert_threshold*100}%"
            self._trigger_alert(health)

        return health

    def _trigger_alert(self, health: dict):
        """触发告警"""
        now = datetime.now()
        # 避免重复告警（5分钟内只告警一次）
        if (self._last_alert_time is None or
            now - self._last_alert_time > timedelta(minutes=5)):
            logger.warning(f"Cache health warning: {health}")
            self._last_alert_time = now
```

---

## 8. 配置管理

### 8.1 配置文件

```python
# backend/app/config.py (扩展)

class Settings(BaseSettings):
    """Application settings"""

    # ... 现有配置 ...

    # Cache settings
    cache_enabled: bool = True
    cache_l1_max_size: int = 10000
    cache_l2_enabled: bool = True
    cache_sqlite_path: str = "./data/cache.db"
    cache_sqlite_cleanup_interval: int = 3600  # 1小时清理一次过期缓存

    # Cache TTL settings (seconds)
    cache_ttl_stock_list: int = 14400      # 4小时
    cache_ttl_kline_history: int = 86400   # 24小时
    cache_ttl_kline_today: int = 300       # 5分钟
    cache_ttl_realtime: int = 3            # 3秒
    cache_ttl_fundamental: int = 21600     # 6小时
    cache_ttl_market_snapshot: int = 300   # 5分钟

    # Cache warm settings
    cache_warm_on_startup: bool = True
    cache_warm_popular_stocks: List[str] = [
        "000001.SZ", "600519.SH", "000858.SZ"
    ]
```

### 8.2 环境变量

```env
# .env

# Cache Configuration
CACHE_ENABLED=true
CACHE_L1_MAX_SIZE=10000
CACHE_L2_ENABLED=true
CACHE_SQLITE_PATH=./data/cache.db
CACHE_SQLITE_CLEANUP_INTERVAL=3600

# Cache TTL (seconds)
CACHE_TTL_STOCK_LIST=14400
CACHE_TTL_KLINE_HISTORY=86400
CACHE_TTL_REALTIME=3

# Warm-up
CACHE_WARM_ON_STARTUP=true
```

---

## 9. 实施计划

### 第一阶段：基础重构（优先级：高）

1. 创建 `CacheManager` 统一管理类
2. 实现内存缓存后端 `MemoryCacheBackend`
3. 实现 SQLite 缓存后端 `SQLiteCacheBackend`
4. 重构 `data_fetcher.py`，集成新缓存层
5. 添加 K 线数据缓存
6. 添加缓存配置到 `config.py`

### 第二阶段：功能增强（优先级：中）

1. 实现缓存预热机制
2. 添加批量请求优化
3. 实现缓存监控 API
4. 添加缓存统计日志

### 第三阶段：持久化与运维增强（优先级：低）

1. 增加过期数据定期清理与文件压缩（VACUUM）
2. 增加 SQLite 锁竞争监控与重试策略
3. 实现缓存失效通知/批量失效机制

---

## 10. 预期收益

| 指标 | 优化前 | 优化后（预期） |
|------|--------|---------------|
| API 响应时间（P99） | ~500ms | ~50ms |
| AKShare 调用频率 | 高 | 降低 80% |
| 内存占用 | 低 | 适度增加（可控） |
| 缓存命中率 | 无监控 | >90% |
| 冷启动时间 | 高 | 显著降低 |

---

## 11. 风险与应对

| 风险 | 影响 | 应对措施 |
|------|------|---------|
| 内存溢出 | 服务崩溃 | 设置缓存大小上限，监控内存使用 |
| 缓存数据过期 | 数据不一致 | 合理设置 TTL，提供手动刷新接口 |
| SQLite 锁竞争/IO 异常 | 缓存读写失败 | L1 缓存兜底，启用 WAL/重试与定期备份 |
| 缓存文件膨胀 | 磁盘占用上升/读写变慢 | 定期清理过期记录 + VACUUM，限制 L2 缓存范围 |
| 预热失败 | 首次请求慢 | 后台重试，错误告警 |

---

## 12. 参考资料

- [cachetools 文档](https://cachetools.readthedocs.io/)
- [SQLite 文档](https://www.sqlite.org/docs.html)
- [aiosqlite 文档](https://github.com/omnilib/aiosqlite)
- [FastAPI 缓存最佳实践](https://fastapi.tiangolo.com/advanced/caching/)
