# 缓存策略优化方案

## 1. 现状分析

### 1.1 当前缓存实现

| 模块 | 缓存类型 | 缓存容量 | TTL | 缓存内容 |
|------|---------|---------|-----|---------|
| `data_fetcher.py` | TTLCache | 1 | 1小时 | 股票列表 |
| `stock_screener.py` | TTLCache | 1 | 5分钟 | 全市场股票快照 |
| `fundamental_analyzer.py` | TTLCache | 100 | 30分钟 | 基本面数据 |
| `config.py` | lru_cache | 1 | 永久 | 配置实例 |

### 1.2 存在的问题

1. **缓存策略分散**：各模块独立实现缓存，缺乏统一管理
2. **K线数据无缓存**：每次请求都调用 AKShare API，造成不必要的网络开销
3. **实时行情无缓存**：高频请求场景下 API 压力大
4. **硬编码配置**：TTL 等参数硬编码，无法动态调整
5. **无分布式支持**：仅支持单进程内存缓存，无法横向扩展
6. **无缓存监控**：缺少命中率、内存占用等监控指标
7. **无预热机制**：冷启动时首次请求延迟较高
8. **无失效通知**：缓存失效时无法主动通知订阅者

---

## 2. 优化目标

1. **统一缓存管理**：建立集中式缓存管理模块
2. **分层缓存架构**：L1（内存） + L2（Redis）两级缓存
3. **智能缓存策略**：根据数据特性设置不同的缓存策略
4. **可观测性**：提供缓存监控指标
5. **高可用**：支持缓存降级和故障恢复

---

## 3. 缓存架构设计

### 3.1 分层缓存架构

```
┌─────────────────────────────────────────────────────────┐
│                      应用层                              │
├─────────────────────────────────────────────────────────┤
│                   CacheManager                           │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────┐ │
│  │ 股票列表缓存 │  │ K线数据缓存 │  │ 基本面数据缓存  │ │
│  └─────────────┘  └─────────────┘  └─────────────────┘ │
├─────────────────────────────────────────────────────────┤
│           L1 Cache (本地内存 - TTLCache/LRU)            │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────┐ │
│  │   热点数据   │  │  最近访问   │  │    高频数据     │ │
│  └─────────────┘  └─────────────┘  └─────────────────┘ │
├─────────────────────────────────────────────────────────┤
│               L2 Cache (Redis - 可选)                   │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────┐ │
│  │  持久化数据  │  │  共享数据   │  │   分布式锁     │ │
│  └─────────────┘  └─────────────┘  └─────────────────┘ │
├─────────────────────────────────────────────────────────┤
│                    数据源层                              │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────┐ │
│  │   AKShare   │  │   数据库    │  │    外部 API     │ │
│  └─────────────┘  └─────────────┘  └─────────────────┘ │
└─────────────────────────────────────────────────────────┘
```

### 3.2 缓存分类与策略

| 数据类型 | 更新频率 | 建议 TTL | 缓存层级 | 优先级 |
|---------|---------|---------|---------|--------|
| 股票列表 | 低（每日） | 4小时 | L1 + L2 | 高 |
| 日K线（历史） | 低 | 24小时 | L1 + L2 | 高 |
| 日K线（当日） | 每日收盘 | 至收盘 | L1 | 中 |
| 分钟K线 | 实时 | 1分钟 | L1 | 低 |
| 实时行情 | 实时 | 3秒 | L1 | 低 |
| 全市场快照 | 中 | 5分钟 | L1 + L2 | 高 |
| 公司概况 | 低 | 24小时 | L1 + L2 | 中 |
| 财务报表 | 季度 | 6小时 | L1 + L2 | 中 |
| 分红历史 | 年度 | 24小时 | L1 + L2 | 低 |
| 股东信息 | 季度 | 6小时 | L1 + L2 | 低 |

---

## 4. 核心模块设计

### 4.1 CacheManager 接口设计

```python
# backend/app/core/cache_manager.py

from abc import ABC, abstractmethod
from typing import Any, Optional, Callable, TypeVar
from datetime import timedelta
from enum import Enum
import hashlib
import json

T = TypeVar('T')

class CacheLevel(Enum):
    """缓存层级"""
    L1_MEMORY = "memory"      # 本地内存
    L2_REDIS = "redis"        # Redis
    BOTH = "both"             # 两级缓存


class CacheConfig:
    """缓存配置"""
    def __init__(
        self,
        ttl: timedelta,
        max_size: int = 1000,
        level: CacheLevel = CacheLevel.L1_MEMORY,
        namespace: str = "default",
        serialize: bool = True
    ):
        self.ttl = ttl
        self.max_size = max_size
        self.level = level
        self.namespace = namespace
        self.serialize = serialize


class CacheBackend(ABC):
    """缓存后端抽象接口"""

    @abstractmethod
    async def get(self, key: str) -> Optional[Any]:
        """获取缓存"""
        pass

    @abstractmethod
    async def set(self, key: str, value: Any, ttl: timedelta) -> bool:
        """设置缓存"""
        pass

    @abstractmethod
    async def delete(self, key: str) -> bool:
        """删除缓存"""
        pass

    @abstractmethod
    async def exists(self, key: str) -> bool:
        """检查缓存是否存在"""
        pass

    @abstractmethod
    async def clear_namespace(self, namespace: str) -> int:
        """清除指定命名空间的所有缓存"""
        pass


class CacheManager:
    """统一缓存管理器"""

    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if hasattr(self, '_initialized'):
            return
        self._initialized = True
        self._l1_cache: CacheBackend = None  # 内存缓存
        self._l2_cache: CacheBackend = None  # Redis缓存
        self._stats = CacheStats()

    async def get(
        self,
        key: str,
        config: CacheConfig,
        fetch_func: Optional[Callable[[], T]] = None
    ) -> Optional[T]:
        """
        获取缓存，支持回源加载

        Args:
            key: 缓存键
            config: 缓存配置
            fetch_func: 缓存未命中时的数据获取函数
        """
        full_key = self._build_key(key, config.namespace)

        # 尝试从 L1 获取
        if config.level in (CacheLevel.L1_MEMORY, CacheLevel.BOTH):
            value = await self._l1_cache.get(full_key)
            if value is not None:
                self._stats.record_hit("L1")
                return value

        # 尝试从 L2 获取
        if config.level in (CacheLevel.L2_REDIS, CacheLevel.BOTH):
            value = await self._l2_cache.get(full_key)
            if value is not None:
                self._stats.record_hit("L2")
                # 回填 L1
                if config.level == CacheLevel.BOTH:
                    await self._l1_cache.set(full_key, value, config.ttl)
                return value

        # 缓存未命中，回源加载
        self._stats.record_miss()
        if fetch_func:
            value = await fetch_func() if asyncio.iscoroutinefunction(fetch_func) else fetch_func()
            if value is not None:
                await self.set(key, value, config)
            return value

        return None

    async def set(self, key: str, value: Any, config: CacheConfig) -> bool:
        """设置缓存"""
        full_key = self._build_key(key, config.namespace)

        success = True
        if config.level in (CacheLevel.L1_MEMORY, CacheLevel.BOTH):
            success &= await self._l1_cache.set(full_key, value, config.ttl)
        if config.level in (CacheLevel.L2_REDIS, CacheLevel.BOTH):
            success &= await self._l2_cache.set(full_key, value, config.ttl)

        return success

    def _build_key(self, key: str, namespace: str) -> str:
        """构建完整的缓存键"""
        return f"{namespace}:{key}"

    def get_stats(self) -> dict:
        """获取缓存统计信息"""
        return self._stats.to_dict()


class CacheStats:
    """缓存统计"""
    def __init__(self):
        self.l1_hits = 0
        self.l2_hits = 0
        self.misses = 0

    def record_hit(self, level: str):
        if level == "L1":
            self.l1_hits += 1
        else:
            self.l2_hits += 1

    def record_miss(self):
        self.misses += 1

    @property
    def hit_rate(self) -> float:
        total = self.l1_hits + self.l2_hits + self.misses
        return (self.l1_hits + self.l2_hits) / total if total > 0 else 0

    def to_dict(self) -> dict:
        return {
            "l1_hits": self.l1_hits,
            "l2_hits": self.l2_hits,
            "misses": self.misses,
            "hit_rate": round(self.hit_rate * 100, 2)
        }
```

### 4.2 内存缓存后端实现

```python
# backend/app/core/cache_backends/memory.py

from cachetools import TTLCache
from datetime import timedelta
from typing import Any, Optional, Dict
import threading
import asyncio

class MemoryCacheBackend(CacheBackend):
    """基于 cachetools 的内存缓存后端"""

    def __init__(self, default_max_size: int = 10000):
        self._caches: Dict[str, TTLCache] = {}
        self._lock = threading.RLock()
        self._default_max_size = default_max_size

    def _get_or_create_cache(self, namespace: str, ttl: timedelta, max_size: int) -> TTLCache:
        """获取或创建指定命名空间的缓存"""
        cache_key = f"{namespace}:{int(ttl.total_seconds())}"
        with self._lock:
            if cache_key not in self._caches:
                self._caches[cache_key] = TTLCache(
                    maxsize=max_size,
                    ttl=ttl.total_seconds()
                )
            return self._caches[cache_key]

    async def get(self, key: str) -> Optional[Any]:
        # 遍历所有缓存查找（简化实现）
        for cache in self._caches.values():
            if key in cache:
                return cache[key]
        return None

    async def set(self, key: str, value: Any, ttl: timedelta) -> bool:
        try:
            namespace = key.split(':')[0] if ':' in key else 'default'
            cache = self._get_or_create_cache(namespace, ttl, self._default_max_size)
            cache[key] = value
            return True
        except Exception:
            return False

    async def delete(self, key: str) -> bool:
        for cache in self._caches.values():
            if key in cache:
                del cache[key]
                return True
        return False

    async def exists(self, key: str) -> bool:
        for cache in self._caches.values():
            if key in cache:
                return True
        return False

    async def clear_namespace(self, namespace: str) -> int:
        count = 0
        keys_to_delete = []
        for cache_key, cache in self._caches.items():
            if cache_key.startswith(namespace):
                count += len(cache)
                keys_to_delete.append(cache_key)

        for key in keys_to_delete:
            del self._caches[key]

        return count
```

### 4.3 Redis 缓存后端实现（可选）

```python
# backend/app/core/cache_backends/redis.py

import redis.asyncio as redis
from datetime import timedelta
from typing import Any, Optional
import json
import pickle

class RedisCacheBackend(CacheBackend):
    """Redis 缓存后端"""

    def __init__(self, redis_url: str = "redis://localhost:6379/0"):
        self._redis: Optional[redis.Redis] = None
        self._redis_url = redis_url

    async def connect(self):
        """连接 Redis"""
        if self._redis is None:
            self._redis = redis.from_url(
                self._redis_url,
                encoding="utf-8",
                decode_responses=False
            )

    async def disconnect(self):
        """断开连接"""
        if self._redis:
            await self._redis.close()
            self._redis = None

    async def get(self, key: str) -> Optional[Any]:
        if not self._redis:
            return None
        try:
            value = await self._redis.get(key)
            if value:
                return pickle.loads(value)
            return None
        except Exception as e:
            print(f"Redis get error: {e}")
            return None

    async def set(self, key: str, value: Any, ttl: timedelta) -> bool:
        if not self._redis:
            return False
        try:
            serialized = pickle.dumps(value)
            await self._redis.setex(key, int(ttl.total_seconds()), serialized)
            return True
        except Exception as e:
            print(f"Redis set error: {e}")
            return False

    async def delete(self, key: str) -> bool:
        if not self._redis:
            return False
        try:
            await self._redis.delete(key)
            return True
        except Exception as e:
            print(f"Redis delete error: {e}")
            return False

    async def exists(self, key: str) -> bool:
        if not self._redis:
            return False
        try:
            return await self._redis.exists(key) > 0
        except Exception:
            return False

    async def clear_namespace(self, namespace: str) -> int:
        if not self._redis:
            return 0
        try:
            cursor = 0
            count = 0
            while True:
                cursor, keys = await self._redis.scan(
                    cursor=cursor,
                    match=f"{namespace}:*",
                    count=100
                )
                if keys:
                    await self._redis.delete(*keys)
                    count += len(keys)
                if cursor == 0:
                    break
            return count
        except Exception as e:
            print(f"Redis clear_namespace error: {e}")
            return 0
```

---

## 5. 数据获取层缓存集成

### 5.1 K线数据缓存优化

```python
# backend/app/core/data_fetcher.py (优化后)

from datetime import timedelta
from app.core.cache_manager import CacheManager, CacheConfig, CacheLevel

# 缓存配置
CACHE_CONFIGS = {
    "stock_list": CacheConfig(
        ttl=timedelta(hours=4),
        max_size=1,
        level=CacheLevel.BOTH,
        namespace="stock"
    ),
    "daily_kline_history": CacheConfig(
        ttl=timedelta(hours=24),
        max_size=500,
        level=CacheLevel.BOTH,
        namespace="kline"
    ),
    "daily_kline_today": CacheConfig(
        ttl=timedelta(minutes=5),
        max_size=500,
        level=CacheLevel.L1_MEMORY,
        namespace="kline"
    ),
    "realtime_quote": CacheConfig(
        ttl=timedelta(seconds=3),
        max_size=1000,
        level=CacheLevel.L1_MEMORY,
        namespace="quote"
    ),
    "intraday": CacheConfig(
        ttl=timedelta(seconds=60),
        max_size=500,
        level=CacheLevel.L1_MEMORY,
        namespace="intraday"
    )
}

class StockDataFetcher:
    """优化后的股票数据获取器"""

    _cache = CacheManager()

    @classmethod
    async def get_daily_kline_cached(
        cls,
        code: str,
        start_date: str,
        end_date: str,
        adjust: str = "qfq"
    ) -> pd.DataFrame:
        """带缓存的日K线获取"""

        # 判断是否包含当日数据
        today = datetime.now().strftime("%Y%m%d")
        is_today_included = end_date >= today

        # 选择缓存配置
        config = (CACHE_CONFIGS["daily_kline_today"]
                  if is_today_included
                  else CACHE_CONFIGS["daily_kline_history"])

        cache_key = f"kline:{code}:{start_date}:{end_date}:{adjust}"

        # 定义回源函数
        async def fetch():
            return await cls.get_daily_kline_async(code, start_date, end_date, adjust)

        return await cls._cache.get(cache_key, config, fetch)

    @classmethod
    async def get_realtime_quote_cached(cls, code: str) -> Optional[Dict[str, Any]]:
        """带缓存的实时行情获取"""

        cache_key = f"quote:{code}"
        config = CACHE_CONFIGS["realtime_quote"]

        async def fetch():
            return await cls.get_realtime_quote_async(code)

        return await cls._cache.get(cache_key, config, fetch)
```

### 5.2 批量请求优化

```python
# backend/app/core/batch_fetcher.py

import asyncio
from typing import List, Dict, Any
from datetime import timedelta

class BatchFetcher:
    """批量数据获取器，支持请求合并和并发控制"""

    def __init__(self, max_concurrent: int = 10):
        self._semaphore = asyncio.Semaphore(max_concurrent)
        self._pending_requests: Dict[str, asyncio.Future] = {}

    async def fetch_multiple_quotes(
        self,
        codes: List[str]
    ) -> Dict[str, Dict[str, Any]]:
        """批量获取多只股票的实时行情"""

        results = {}
        tasks = []

        for code in codes:
            # 检查是否有相同请求正在进行（请求合并）
            if code in self._pending_requests:
                tasks.append((code, self._pending_requests[code]))
            else:
                future = asyncio.ensure_future(self._fetch_single(code))
                self._pending_requests[code] = future
                tasks.append((code, future))

        # 等待所有请求完成
        for code, task in tasks:
            try:
                results[code] = await task
            except Exception as e:
                print(f"Error fetching {code}: {e}")
                results[code] = None
            finally:
                self._pending_requests.pop(code, None)

        return results

    async def _fetch_single(self, code: str) -> Dict[str, Any]:
        """单个请求（带并发控制）"""
        async with self._semaphore:
            return await StockDataFetcher.get_realtime_quote_cached(code)
```

---

## 6. 缓存预热策略

### 6.1 预热管理器

```python
# backend/app/core/cache_warmer.py

import asyncio
from typing import List
from datetime import datetime

class CacheWarmer:
    """缓存预热管理器"""

    def __init__(self):
        self._is_warming = False

    async def warm_on_startup(self):
        """服务启动时预热缓存"""
        if self._is_warming:
            return

        self._is_warming = True
        print("[CacheWarmer] Starting cache warm-up...")

        try:
            # 1. 预热股票列表
            await self._warm_stock_list()

            # 2. 预热热门股票的K线数据
            await self._warm_popular_stocks()

            # 3. 预热全市场快照（用于筛选器）
            await self._warm_market_snapshot()

            print("[CacheWarmer] Cache warm-up completed")
        except Exception as e:
            print(f"[CacheWarmer] Warm-up failed: {e}")
        finally:
            self._is_warming = False

    async def _warm_stock_list(self):
        """预热股票列表"""
        print("[CacheWarmer] Warming stock list...")
        await StockDataFetcher.get_stock_list_async()

    async def _warm_popular_stocks(self):
        """预热热门股票数据"""
        # 定义热门股票列表（可从配置或数据库读取）
        popular_codes = [
            "000001.SZ",  # 平安银行
            "600519.SH",  # 贵州茅台
            "000858.SZ",  # 五粮液
            "601318.SH",  # 中国平安
            "600036.SH",  # 招商银行
        ]

        print(f"[CacheWarmer] Warming {len(popular_codes)} popular stocks...")

        tasks = [
            StockDataFetcher.get_daily_kline_cached(
                code,
                start_date=(datetime.now() - timedelta(days=365)).strftime("%Y%m%d"),
                end_date=datetime.now().strftime("%Y%m%d")
            )
            for code in popular_codes
        ]

        await asyncio.gather(*tasks, return_exceptions=True)

    async def _warm_market_snapshot(self):
        """预热全市场快照"""
        print("[CacheWarmer] Warming market snapshot...")
        await StockScreener.get_all_stocks_data()


# 在 FastAPI 启动时调用
# backend/app/main.py
from app.core.cache_warmer import CacheWarmer

@app.on_event("startup")
async def startup_event():
    warmer = CacheWarmer()
    # 后台执行预热，不阻塞启动
    asyncio.create_task(warmer.warm_on_startup())
```

---

## 7. 缓存监控与运维

### 7.1 监控 API

```python
# backend/app/api/v1/cache.py

from fastapi import APIRouter
from app.core.cache_manager import CacheManager

router = APIRouter()

@router.get("/stats")
async def get_cache_stats():
    """获取缓存统计信息"""
    cache = CacheManager()
    return {
        "status": "ok",
        "stats": cache.get_stats(),
        "timestamp": datetime.now().isoformat()
    }

@router.post("/clear/{namespace}")
async def clear_cache(namespace: str):
    """清除指定命名空间的缓存"""
    cache = CacheManager()
    count = await cache.clear_namespace(namespace)
    return {
        "status": "ok",
        "cleared_count": count,
        "namespace": namespace
    }

@router.post("/warm")
async def trigger_warm():
    """触发缓存预热"""
    warmer = CacheWarmer()
    asyncio.create_task(warmer.warm_on_startup())
    return {"status": "ok", "message": "Warm-up started"}
```

### 7.2 日志与告警

```python
# backend/app/core/cache_monitor.py

import logging
from datetime import datetime, timedelta

logger = logging.getLogger("cache")

class CacheMonitor:
    """缓存监控器"""

    def __init__(self, alert_threshold: float = 0.5):
        self._alert_threshold = alert_threshold  # 命中率告警阈值
        self._last_alert_time = None

    async def check_health(self) -> dict:
        """检查缓存健康状态"""
        cache = CacheManager()
        stats = cache.get_stats()

        health = {
            "status": "healthy",
            "hit_rate": stats["hit_rate"],
            "l1_hits": stats["l1_hits"],
            "l2_hits": stats["l2_hits"],
            "misses": stats["misses"],
            "timestamp": datetime.now().isoformat()
        }

        # 检查命中率
        if stats["hit_rate"] < self._alert_threshold * 100:
            health["status"] = "warning"
            health["message"] = f"Cache hit rate below {self._alert_threshold*100}%"
            self._trigger_alert(health)

        return health

    def _trigger_alert(self, health: dict):
        """触发告警"""
        now = datetime.now()
        # 避免重复告警（5分钟内只告警一次）
        if (self._last_alert_time is None or
            now - self._last_alert_time > timedelta(minutes=5)):
            logger.warning(f"Cache health warning: {health}")
            self._last_alert_time = now
```

---

## 8. 配置管理

### 8.1 配置文件

```python
# backend/app/config.py (扩展)

class Settings(BaseSettings):
    """Application settings"""

    # ... 现有配置 ...

    # Cache settings
    cache_enabled: bool = True
    cache_l1_max_size: int = 10000
    cache_l2_enabled: bool = False
    cache_redis_url: str = "redis://localhost:6379/0"

    # Cache TTL settings (seconds)
    cache_ttl_stock_list: int = 14400      # 4小时
    cache_ttl_kline_history: int = 86400   # 24小时
    cache_ttl_kline_today: int = 300       # 5分钟
    cache_ttl_realtime: int = 3            # 3秒
    cache_ttl_fundamental: int = 21600     # 6小时
    cache_ttl_market_snapshot: int = 300   # 5分钟

    # Cache warm settings
    cache_warm_on_startup: bool = True
    cache_warm_popular_stocks: List[str] = [
        "000001.SZ", "600519.SH", "000858.SZ"
    ]
```

### 8.2 环境变量

```env
# .env

# Cache Configuration
CACHE_ENABLED=true
CACHE_L1_MAX_SIZE=10000
CACHE_L2_ENABLED=false
CACHE_REDIS_URL=redis://localhost:6379/0

# Cache TTL (seconds)
CACHE_TTL_STOCK_LIST=14400
CACHE_TTL_KLINE_HISTORY=86400
CACHE_TTL_REALTIME=3

# Warm-up
CACHE_WARM_ON_STARTUP=true
```

---

## 9. 实施计划

### 第一阶段：基础重构（优先级：高）

1. 创建 `CacheManager` 统一管理类
2. 实现内存缓存后端 `MemoryCacheBackend`
3. 重构 `data_fetcher.py`，集成新缓存层
4. 添加 K 线数据缓存
5. 添加缓存配置到 `config.py`

### 第二阶段：功能增强（优先级：中）

1. 实现缓存预热机制
2. 添加批量请求优化
3. 实现缓存监控 API
4. 添加缓存统计日志

### 第三阶段：分布式支持（优先级：低）

1. 实现 Redis 缓存后端
2. 支持两级缓存架构
3. 添加分布式锁支持
4. 实现缓存失效通知

---

## 10. 预期收益

| 指标 | 优化前 | 优化后（预期） |
|------|--------|---------------|
| API 响应时间（P99） | ~500ms | ~50ms |
| AKShare 调用频率 | 高 | 降低 80% |
| 内存占用 | 低 | 适度增加（可控） |
| 缓存命中率 | 无监控 | >90% |
| 冷启动时间 | 高 | 显著降低 |

---

## 11. 风险与应对

| 风险 | 影响 | 应对措施 |
|------|------|---------|
| 内存溢出 | 服务崩溃 | 设置缓存大小上限，监控内存使用 |
| 缓存数据过期 | 数据不一致 | 合理设置 TTL，提供手动刷新接口 |
| Redis 故障 | 缓存失效 | L1 缓存兜底，Redis 降级策略 |
| 预热失败 | 首次请求慢 | 后台重试，错误告警 |

---

## 12. 参考资料

- [cachetools 文档](https://cachetools.readthedocs.io/)
- [redis-py 文档](https://redis-py.readthedocs.io/)
- [FastAPI 缓存最佳实践](https://fastapi.tiangolo.com/advanced/caching/)
